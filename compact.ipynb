{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef test_b():\\n    PATH_TO_IMAGES = \\'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\train_img\\\\train2.txt\\'\\n    obr = np.loadtxt(PATH_TO_IMAGES, dtype=np.float)\\n    obr = obr.reshape (1, 1, 256, 256).astype(\\'float32\\')\\n    obr = torch.from_numpy(obr)\\n    print(\"testb dtype::\"+str(obr.dtype))\\n    print(\"testb size:\"+str(obr.size))\\n    print(\"testtb ndim:\"+str(obr.ndim))\\n    print(\"testtb shape:\"+str(obr.shape))      \\n\\n    model = UNET(in_channels=1, out_channels=1)\\n    preds = model(obr)\\n\\n    yz = preds.detach().numpy()\\n    print()\\n    print(yz.shape)\\n\\n    arr = yz\\n    arr_ = np.squeeze(arr)\\n    plt.imshow(arr_)\\n    plt.show()\\n\\n    \\nif __name__ == \"__main__\":\\n    test_a()\\n    test_b()\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unet model implementation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n",
    "    ):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "    \n",
    "#Test code with generated data for architecture testing\n",
    "\"\"\"\n",
    "def test_a():\n",
    "    x = torch.randn((3, 1, 256, 256))    \n",
    "    print(x.dtype)\n",
    "    print(x.size)\n",
    "    print(\"dimenze:\" + str(x.ndim))\n",
    "    print(x.shape)\n",
    "    \n",
    "    model = UNET(in_channels=1, out_channels=1)\n",
    "    preds = model(x)\n",
    "    print(preds.shape)\n",
    "    print(x.shape)\n",
    "    assert preds.shape == x.shape \n",
    "\"\"\"\n",
    "#Test code with preprocessed data for architecture testing\n",
    "\"\"\"\n",
    "def test_b():\n",
    "    PATH_TO_IMAGES = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\train_img\\\\train2.txt'\n",
    "    obr = np.loadtxt(PATH_TO_IMAGES, dtype=np.float)\n",
    "    obr = obr.reshape (1, 1, 256, 256).astype('float32')\n",
    "    obr = torch.from_numpy(obr)\n",
    "    print(\"testb dtype::\"+str(obr.dtype))\n",
    "    print(\"testb size:\"+str(obr.size))\n",
    "    print(\"testtb ndim:\"+str(obr.ndim))\n",
    "    print(\"testtb shape:\"+str(obr.shape))      \n",
    "\n",
    "    model = UNET(in_channels=1, out_channels=1)\n",
    "    preds = model(obr)\n",
    "\n",
    "    yz = preds.detach().numpy()\n",
    "    print()\n",
    "    print(yz.shape)\n",
    "\n",
    "    arr = yz\n",
    "    arr_ = np.squeeze(arr)\n",
    "    plt.imshow(arr_)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test_a()\n",
    "    test_b()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function #1 (to be tested with my code)\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import import_ipynb \n",
    "\n",
    "\n",
    "sys.path.append(os.getcwd())  # path contains python_file.py\n",
    "\n",
    "import time\n",
    "\n",
    "def train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=1):\n",
    "    start = time.time()\n",
    "    #model.cuda()\n",
    "\n",
    "    train_loss, valid_loss = [], []\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set trainind mode = true\n",
    "                dataloader = train_dl\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                dataloader = valid_dl\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "\n",
    "            step = 0\n",
    "            \n",
    "            # iterate over data\n",
    "            for x, y in dataloader:\n",
    "                #x = x.cuda()\n",
    "                #y = y.cuda()\n",
    "                step += 1\n",
    "            \n",
    "                # forward pass\n",
    "                if phase == 'train':\n",
    "                    # zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(x)\n",
    "                    loss = loss_fn(outputs, y)\n",
    "\n",
    "                    # the backward pass frees the graph memory, so there is no \n",
    "                    # need for torch.no_grad in this training pass\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    # scheduler.step()\n",
    "\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(x)\n",
    "                        loss = loss_fn(outputs, y.long())\n",
    "\n",
    "                # stats - whatever is the phase\n",
    "                acc = acc_fn(outputs, y)\n",
    "\n",
    "                running_acc  += acc*dataloader.batch_size\n",
    "                running_loss += loss*dataloader.batch_size \n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    # clear_output(wait=True)\n",
    "                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n",
    "                    # print(torch.cuda.memory_summary())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_acc / len(dataloader.dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "    \n",
    "    return train_loss, valid_loss    \n",
    "\n",
    "def acc_metric(predb, yb):\n",
    "    return (predb.argmax(dim=1) == yb.cuda()).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader for data\n",
    "import os\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MicroscopyDataset (Dataset):\n",
    "    \n",
    "    \"\"\"Loading data fuction\"\"\"\n",
    "    \n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        print(\"Debug: -here-\")\n",
    "        #print(\"Path to image:\" + str(image_dir))\n",
    "        #print(\"Path to mask:\" + str(mask_dir))\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir   \n",
    "        #list of all files in folder\n",
    "        self.images = os.listdir(image_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        print(\"Length: -here-\")\n",
    "        #Length of the dataset\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        print(\"Get: -here-\")\n",
    "        #Path for image and mask\n",
    "        image_path = os.path.join(self.image_dir, self.images[i])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[i])\n",
    "        print(str(image_path))\n",
    "        print(str(mask_path))\n",
    "        #load data\n",
    "        image = np.loadtxt(image_path, dtype = np.float32) \n",
    "        mask = np.loadtxt(mask_path, dtype = np.float32)\n",
    "        image = image.reshape (1, 1, 256, 256).astype('float32') \n",
    "        mask = mask.reshape (1, 1, 256, 256).astype('float32')\n",
    "        #image = torch.from_numpy(image)\n",
    "        #mask = torch.from_numpy(mask)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility helpers (not all yet used TODO)\n",
    "import torch\n",
    "import torchvision\n",
    "import import_ipynb \n",
    "from load_dataset import MicroscopyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "def get_loaders(\n",
    "    train_dir,\n",
    "    train_maskdir,\n",
    "    val_dir,\n",
    "    val_maskdir,\n",
    "    batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "):\n",
    "    train_ds = MicroscopyDataset(\n",
    "        image_dir=train_dir,\n",
    "        mask_dir=train_maskdir,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = MicroscopyDataset(\n",
    "        image_dir=val_dir,\n",
    "        mask_dir=val_maskdir,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def check_accuracy(loader, model, device=\"cuda\"):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x\n",
    "            y = y\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).unsqueeze(1)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            dice_score += (2 * (preds * y).sum()) / (\n",
    "                (preds + y).sum() + 1e-8\n",
    "            )\n",
    "            \n",
    "    print(\n",
    "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
    "    )\n",
    "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
    "    model.train()\n",
    "\n",
    "def save_predictions_as_imgs(\n",
    "    loader, model, folder=\"saved_images/\", device=\"cuda\"\n",
    "):\n",
    "    model.eval()\n",
    "    for idx, (x, y) in enumerate(loader):\n",
    "        x = x.to(device=device)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "        torchvision.utils.save_image(\n",
    "            preds, f\"{folder}/pred_{idx}.png\"\n",
    "        )\n",
    "        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function #2 (to be tested with my code)\n",
    "import torch\n",
    "import torchvision\n",
    "import import_ipynb \n",
    "from load_dataset import MicroscopyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Device: cpu\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_img\\\\val1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e87f2e177ead>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0mcheck_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsk_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-15acca24dbb6>\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[1;34m(loader, model, device)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mload_dataset.ipynb\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, i)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2928\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccept_warnings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2930\u001b[1;33m     raise UnidentifiedImageError(\n\u001b[0m\u001b[0;32m   2931\u001b[0m         \u001b[1;34m\"cannot identify image file %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2932\u001b[0m     )\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_img\\\\val1.txt'"
     ]
    }
   ],
   "source": [
    "#Here is where all the main code should be stored\n",
    "PATH_TO_IMAGES = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\train_img'\n",
    "PATH_TO_MASKS = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\train_mask'\n",
    "PATH_TO_VAL_IMG = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_img'\n",
    "PATH_TO_VAL_MASK = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_mask'\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 3\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "\n",
    "\"\"\"\n",
    "obr = np.loadtxt(PATH_TO_IMAGES, dtype=np.float)\n",
    "obr = obr.reshape (1, 1, 256, 256).astype('float32')\n",
    "obr = torch.from_numpy(obr)\n",
    "print(\"obr dtype::\"+str(obr.dtype))\n",
    "print(\"obr size:\"+str(obr.size))\n",
    "print(\"obr ndim:\"+str(obr.ndim))\n",
    "print(\"obr shape:\"+str(obr.shape))\n",
    "\n",
    "msk = np.loadtxt(PATH_TO_MASKS, dtype=np.float)\n",
    "msk = msk.reshape (1, 1, 256, 256).astype('float32')\n",
    "msk = torch.from_numpy(msk)\n",
    "print(\"mask dtype::\"+str(msk.dtype))\n",
    "print(\"mask size:\"+str(msk.size))\n",
    "print(\"mask ndim:\"+str(msk.ndim))\n",
    "print(\"mask shape:\"+str(msk.shape))\n",
    "\"\"\"\n",
    "\n",
    "print(\"Selected Device: \"+ str(DEVICE))\n",
    "model = UNET(in_channels=1, out_channels=1).to(DEVICE)\n",
    "obr_loader, msk_loader = get_loaders(\n",
    "    PATH_TO_IMAGES, \n",
    "    PATH_TO_MASKS, \n",
    "    PATH_TO_VAL_IMG, \n",
    "    PATH_TO_VAL_MASK, \n",
    "    BATCH_SIZE,\n",
    "    NUM_WORKERS,\n",
    "    PIN_MEMORY,\n",
    ")\n",
    "\n",
    "\n",
    "#preds = model(obr)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\"\"\"\n",
    "detached_preds = preds.detach().numpy()\n",
    "arr = detached_preds\n",
    "arr_ = np.squeeze(arr)\n",
    "plt.imshow(arr_)\n",
    "plt.show()\n",
    "\n",
    "detached_mask = msk.detach().numpy()\n",
    "arr = detached_mask\n",
    "arr_ = np.squeeze(arr)\n",
    "plt.imshow(arr_)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "#train_loss, valid_loss = train(model, obr, msk, loss_fn, opt, acc_metric, epochs = 1)\n",
    "if LOAD_MODEL:\n",
    "        load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
    "\n",
    "    \n",
    "check_accuracy(msk_loader, model, device=DEVICE)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Nelze vytvořit soubor, který již existuje: 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_mask\\\\val10.txt' -> 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_mask\\\\val2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6d229f0052a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m#im = Image.fromarray(image).convert(\"RGB\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m#im.save(PATH_TO_VAL_MASK+\"val\"+str(i)+\".png\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH_TO_VAL_MASK\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPATH_TO_VAL_MASK\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"val\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Nelze vytvořit soubor, který již existuje: 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_mask\\\\val10.txt' -> 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_mask\\\\val2.txt'"
     ]
    }
   ],
   "source": [
    "#Script for img conversion/rename\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "PATH_TO_IMAGES = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\train_img\\\\'\n",
    "PATH_TO_MASKS = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\train_mask\\\\'\n",
    "PATH_TO_VAL_IMG = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_img\\\\'\n",
    "PATH_TO_VAL_MASK = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\skola\\\\rocnik_3\\\\bakalarka\\\\implementace\\\\github_implementace\\\\CNN_UNet\\\\val_mask\\\\'\n",
    "\"\"\"\n",
    "files = os.listdir(PATH_TO_VAL_IMG)\n",
    "print(files)\n",
    "i = 1\n",
    "for file in files:\n",
    "    image = np.loadtxt(PATH_TO_VAL_IMG+str(file), dtype = np.float32) \n",
    "    \n",
    "    #print(\"type:\"+str(type(image)))\n",
    "    #print(\"ndim:\"+str(image.ndim))\n",
    "    #print(\"shape:\"+str(image.shape))\n",
    "    #print(\"size\"+str(image.size))\n",
    "    \n",
    "    #image = image.reshape (1, 1, 256, 256).astype('float32') \n",
    "    \n",
    "    #im = Image.fromarray(image).convert(\"L\")\n",
    "    #im.save(PATH_TO_VAL_IMG+\"val\"+str(i)+\".png\")\n",
    "    os.rename(PATH_TO_VAL_IMG+str(file), PATH_TO_VAL_IMG+\"val\"+str(i)+\".txt\")\n",
    "    i = i+1\n",
    "\"\"\"\n",
    "files = os.listdir(PATH_TO_VAL_MASK)\n",
    "i = 1\n",
    "for file in files:\n",
    "    image = np.loadtxt(PATH_TO_VAL_MASK+str(file), dtype = np.float32) \n",
    "    \"\"\"\n",
    "    print(\"type:\"+str(type(image)))\n",
    "    print(\"ndim:\"+str(image.ndim))\n",
    "    print(\"shape:\"+str(image.shape))\n",
    "    print(\"size\"+str(image.size))\n",
    "    \"\"\"\n",
    "    #image = image.reshape (1, 1, 256, 256).astype('float32') \n",
    "    \n",
    "    #im = Image.fromarray(image).convert(\"RGB\")\n",
    "    #im.save(PATH_TO_VAL_MASK+\"val\"+str(i)+\".png\")\n",
    "    os.rename(PATH_TO_VAL_MASK+str(file), PATH_TO_VAL_MASK+\"val\"+str(i)+\".txt\")\n",
    "    i = i+1\n",
    "    \n",
    "files = os.listdir(PATH_TO_IMAGES)\n",
    "i = 1\n",
    "for file in files:\n",
    "    image = np.loadtxt(PATH_TO_IMAGES+str(file), dtype = np.float32) \n",
    "    \"\"\"\n",
    "    print(\"type:\"+str(type(image)))\n",
    "    print(\"ndim:\"+str(image.ndim))\n",
    "    print(\"shape:\"+str(image.shape))\n",
    "    print(\"size\"+str(image.size))\n",
    "    \"\"\"\n",
    "    #image = image.reshape (1, 1, 256, 256).astype('float32') \n",
    "    \n",
    "    #im = Image.fromarray(image).convert(\"L\")\n",
    "    #im.save(PATH_TO_IMAGES+\"train\"+str(i)+\".png\")\n",
    "    os.rename(PATH_TO_IMAGES+str(file), PATH_TO_IMAGES+\"train\"+str(i)+\".txt\")\n",
    "    i = i+1\n",
    "\n",
    "files = os.listdir(PATH_TO_MASKS)\n",
    "i = 1\n",
    "for file in files:\n",
    "    image = np.loadtxt(PATH_TO_MASKS+str(file), dtype = np.float32) \n",
    "    \"\"\"\n",
    "    print(\"type:\"+str(type(image)))\n",
    "    print(\"ndim:\"+str(image.ndim))\n",
    "    print(\"shape:\"+str(image.shape))\n",
    "    print(\"size\"+str(image.size))\n",
    "    \"\"\"\n",
    "    #image = image.reshape (1, 1, 256, 256).astype('float32') \n",
    "    \n",
    "    #im = Image.fromarray(image).convert(\"L\")\n",
    "    #im.save(PATH_TO_MASKS+\"train\"+str(i)+\".png\")\n",
    "    os.rename(PATH_TO_MASKS+str(file), PATH_TO_MASKS+\"train\"+str(i)+\".txt\")\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
